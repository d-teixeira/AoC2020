{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python Learning Journey\n",
    "\n",
    "Throughout this notebook, I will be posting all my codes for the different Advent of Code challenges. Since I am doing this for learning purposes, I will post my original code, successful or not, efficient or not, and will try to search for better solutions of other programmers to increase my awareness of libraries, methods, functions, best practices and so on. In the end, I expect this notebook to be helpful for my future self and, maybe, for others novice programmers doing these challenges too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first code was really awful in terms of efficiency. I tried to run three for loops that ran forever, I even had to stop the process. Luckily, the results had been found already. This was the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#\n",
    "#data = pd.read_csv('input.txt', header=None)\n",
    "#data.columns = ['Value']\n",
    "#data.iloc[0].values + 10\n",
    "#\n",
    "#for i, val in enumerate(data.Value):\n",
    "#    for i2 in range(len(data)):\n",
    "#        for i3 in range(len(data)):\n",
    "#            if data.iloc[i].values + data.iloc[i2].values + data.iloc[i3].values== 2020:\n",
    "#                entry1 = i\n",
    "#                entry2 = i2\n",
    "#                entry3 = i3\n",
    "#                break\n",
    "#            else:\n",
    "#                continue\n",
    "#\n",
    "#check = data.iloc[entry1].values + data.iloc[entry2].values + data.iloc[entry3].values\n",
    "#ans = data.iloc[entry1].values * data.iloc[entry2].values * data.iloc[entry3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a code from a colleague that I like given the different perspective of the solution. You could find the code here too: https://github.com/ed-hermoreyes/advent_of_code2020/blob/main/Advent-of-code-2020.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776064\n",
      "776064\n",
      "6964490\n"
     ]
    }
   ],
   "source": [
    "### PART ONE ####\n",
    "with open('day1.txt','r') as doc:\n",
    "    numbers = [int(i) for i in doc.read().splitlines()]\n",
    "    \n",
    "for num in numbers:\n",
    "    if (2020-num) in numbers:\n",
    "        print(num*numbers[numbers.index(2020-num)])\n",
    "        \n",
    "### PART TWO ###\n",
    "from itertools import combinations\n",
    "\n",
    "num_combi = combinations(numbers, 3)\n",
    "\n",
    "def product(sequence):\n",
    "    initial = 1\n",
    "    for i in sequence:\n",
    "        initial *= i\n",
    "    return initial\n",
    "\n",
    "for comb in num_combi:\n",
    "    if sum(comb) == 2020:\n",
    "        print(product(comb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really like the simplicity of the first part of the code, to what I think that more thoughts most be put in a coding problem in order to find other perspectives if one is not efficient enough. Also, like always, searching on the web or asking others for correction, ideas, etc. would be of help. In the second part, I got to know the itertools library, definitely one that I will keep in mind.\n",
    "\n",
    "Searching on the web, I found this article on the used of for loops and some better alternative to know when the former is not that efficient. https://medium.com/python-pandemonium/never-write-for-loops-again-91a5a4c84baf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Part 1:  636\n",
      "Result Part 2:  588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('day2.txt', header=None, delimiter=' ')\n",
    "data.columns = ['len','char','pass']\n",
    "data['len'] = [x.split('-') for x in data['len']]\n",
    "data['char'] = [x.strip(':') for x in data['char']]\n",
    "\n",
    "### PART ONE ###\n",
    "\n",
    "data['valid'] = 0\n",
    "for i,row in data.iterrows():\n",
    "    letter = row['char']\n",
    "    count = row['pass'].count(letter)\n",
    "    r = range(int(row.len[0]),int(row.len[1])+1)\n",
    "    if count in r:\n",
    "        data.loc[i, 'valid'] = 1\n",
    "        \n",
    "print('Result Part 1: ', data.valid.sum())\n",
    "\n",
    "### PART TWO ###\n",
    "\n",
    "data['valid2'] = 0\n",
    "for i,row in data.iterrows():\n",
    "    letter = row['char']\n",
    "    p1 = int(row.len[0]) - 1\n",
    "    p2 = int(row.len[1]) - 1\n",
    "    if row['pass'][p1] == letter and row['pass'][p2] != letter:\n",
    "        data.loc[i, 'valid2'] = 1\n",
    "    elif row['pass'][p1] != letter and row['pass'][p2] == letter:\n",
    "        data.loc[i, 'valid2'] = 1\n",
    "\n",
    "print('Result Part 2: ', data.valid2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "### PART ONE ###\n",
    "text = open('day3.txt').readlines()\n",
    "for i in range(len(text)):\n",
    "    text[i] = text[i]*33\n",
    "    text[i] = text[i].replace('\\n', '')\n",
    "\n",
    "position = 3\n",
    "count = 0 \n",
    "for i,line in enumerate(text):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    loc = line[position]\n",
    "    if loc == '#':\n",
    "        count += 1\n",
    "    position += 3  \n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part I did not have much problems, but I in the second task the code would encounter a problem of scalability in the reproduction of the text in line 4. If a requested slope have a bigger pattern to the right the increase necessity in storage would reduced the efficiency. Also, if different slopes are asked, the text would need to be reproduced (like in line 4) for each slope.\n",
    "\n",
    "Because of that, I looked on the reddit for some inspiration and saw that many people used a rule with remainders of a division to solve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9406609920\n"
     ]
    }
   ],
   "source": [
    "### PART TWO ###\n",
    "import math\n",
    "text = open('day3.txt').readlines()\n",
    "for i in range(len(text)):\n",
    "    text[i] = text[i].replace('\\n', '')\n",
    "\n",
    "def tree_count(text, right, down):\n",
    "    '''\n",
    "        Count the encounter trees in a text following an additive pattern of\n",
    "        characters to the RIGHT and, after that movement, a pattern of lines \n",
    "        DOWN.\n",
    "    '''    \n",
    "    row = down\n",
    "    char = right\n",
    "    count = 0\n",
    "    for i,line in enumerate(text):\n",
    "        if i != row:\n",
    "            continue\n",
    "        if char >= len(line):\n",
    "            location = line[char % len(line)]\n",
    "        else:    \n",
    "            location = line[char]\n",
    "        if location == '#':\n",
    "            count += 1\n",
    "        row += down\n",
    "        char += right\n",
    "    return count\n",
    "\n",
    "slopes = [(1,1),(3,1),(5,1),(7,1),(1,2)]\n",
    "trees_text = [tree_count(text, right=slope[0], down=slope[1]) for slope in slopes]\n",
    "print(math.prod(trees_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I had a problem with the result for a while. The count of trees was ok, but I was using the <code>numpy.prod()</code> for the last operation. It caused what is call a **integer overflow**, which according to [Wikipedia](https://en.wikipedia.org/wiki/Integer_overflow#:~:text=In%20computer%20programming%2C%20an%20integer,than%20the%20minimum%20representable%20value.) is:\n",
    "> _In computer programming, an integer overflow occurs when an arithmetic operation attempts to create a numeric value that is outside of the range that can be represented with a given number of digits â€“ either higher than the maximum or lower than the minimum representable value._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, because of this the function was giving to me a wrong number. The solution was to pass the argument <code>dtype</code> as <code>'int64'</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d6647de18746>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pps['valid'][i] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PART ONE ###\n",
    "import pandas as pd\n",
    "data = open('day4.txt').read()\n",
    "pps = pd.DataFrame(data.split('\\n\\n'), columns=['info'],)\n",
    "pps['valid'] = 0\n",
    "\n",
    "for i, passport in enumerate(pps['info']):\n",
    "    if 'byr' not in passport:\n",
    "        continue\n",
    "    elif 'iyr' not in passport:\n",
    "        continue\n",
    "    elif 'eyr' not in passport:\n",
    "        continue\n",
    "    elif 'hgt' not in passport:\n",
    "        continue\n",
    "    elif 'hcl' not in passport:\n",
    "        continue\n",
    "    elif 'ecl' not in passport:\n",
    "        continue\n",
    "    elif 'pid' not in passport:\n",
    "        continue\n",
    "    else:\n",
    "        pps['valid'][i] = 1\n",
    "\n",
    "sum(pps.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "### PART TWO ###\n",
    "import re\n",
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\datds\\Documents\\GitHub\\AoC2020\")\n",
    "\n",
    "data = open('day4.txt').read().split('\\n\\n')\n",
    "valid = 0\n",
    "\n",
    "for i,passport in enumerate(data):\n",
    "    # BYR test\n",
    "    byr = re.search(r'byr:([\\d]{4})', passport)\n",
    "    if byr == None:\n",
    "        continue\n",
    "    if not (1920 <= int(byr.groups()[0]) <= 2002):\n",
    "        continue\n",
    "    # IYR test\n",
    "    iyr = re.search(r'iyr:([\\d]{4})', passport)\n",
    "    if iyr == None:\n",
    "        continue\n",
    "    if not (2010 <= int(iyr.groups()[0]) <= 2020):\n",
    "        continue\n",
    "    # EYR test\n",
    "    eyr = re.search(r'eyr:([\\d]{4})', passport)\n",
    "    if eyr == None:\n",
    "        continue\n",
    "    if not (2020 <= int(eyr.groups()[0]) <= 2030):\n",
    "        continue\n",
    "    # HGT test\n",
    "    hgt = re.search(r'hgt:([\\d]+)(cm|in)', passport)\n",
    "    if hgt == None:\n",
    "        continue\n",
    "    if hgt.groups()[1] == 'cm':\n",
    "        if not (150 <= int(hgt.groups()[0]) <= 193):\n",
    "            continue\n",
    "    if hgt.groups()[1] == 'in':\n",
    "        if not (59 <= int(hgt.groups()[0]) <= 76):\n",
    "            continue\n",
    "    # HCL test\n",
    "    hcl = re.search(r'hcl:(\\#[\\da-f]{6})', passport)\n",
    "    if hcl == None:\n",
    "        continue\n",
    "    #ECL test\n",
    "    ecl = re.search(r'ecl:(amb|blu|brn|gry|grn|hzl|oth)', passport)\n",
    "    if ecl == None:\n",
    "        continue \n",
    "    #PID test\n",
    "    pid = re.search(r'pid:([\\d]{9})', passport)\n",
    "    if pid == None:\n",
    "        continue\n",
    "    valid += 1\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth challenge was useful to study again the regex syntax. It was really useful the [regex101](https://regex101.com/) builder for this task, which allowed me to wrote and checked my syntax quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PART ONE ###\n",
    "import pandas as pd\n",
    "\n",
    "seats = pd.read_csv('day5.txt', names=['code'])\n",
    "seats['seat'] = None\n",
    "seats['seat_id'] = 0\n",
    "\n",
    "for i, code in enumerate(seats.code):\n",
    "    row = list(range(1,129))\n",
    "    for j in range(0,7):\n",
    "        if code[j] == 'F':\n",
    "            row = row[:int(len(row)/2)]\n",
    "        else:\n",
    "            row = row[int(len(row)/2):]\n",
    "    col = list(range(1,9))\n",
    "    for k in range(7,10):\n",
    "        if code[k] == 'L':\n",
    "            col = col[:int(len(col)/2)]\n",
    "        else:\n",
    "            col = col[int(len(col)/2):]\n",
    "    \n",
    "    seats.at[i , 'seat'] = (row[0] - 1, col[0] - 1)\n",
    "    seats.at[i , 'seat_id'] = (row[0] - 1) * 8 + col[0] - 1 \n",
    "\n",
    "max(seats.seat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743\n"
     ]
    }
   ],
   "source": [
    "### PARTE TWO ###\n",
    "s = seats.sort_values('seat_id').reset_index()\n",
    "\n",
    "i = 1\n",
    "while i < len(s):\n",
    "    prev = s.seat_id[i - 1]\n",
    "    act = s.seat_id[i]\n",
    "    if act - prev == 2:\n",
    "       print(act - 1)\n",
    "       break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem wasn't difficult to resolved with my previous knowledge of python. But I learned a two new functions: <code>.at</code> and <code>.iat</code>, which localize a cell like <code>.loc</code> and <code>.iloc</code> but they are used to get or assign a single value in the cell ([here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html) the documentation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
